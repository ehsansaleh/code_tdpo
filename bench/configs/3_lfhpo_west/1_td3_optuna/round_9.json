{
  "description": "Hyper-parameter optimization for td3 on a low frequency environment",
  "method": "td3",
  "environment": "drop_leg_100hz",
  "total_timesteps": 4000000,
  "rng_seed": [
    0,
    1000,
    2000
  ],
  "policy_kwargs": {
    "layers": [
      64,
      64
    ],
    "activation": "tanh",
    "do_mlp_output_tanh": false,
    "mlp_output_scaling": 1
  },
  "gamma": [
    0.38240116484635556,
    0.364833211418525,
    0.4263244977257581,
    0.4540930914494492,
    0.38315548738691596,
    0.4496142074216961,
    0.4065257767803484,
    0.42132307184312234,
    0.41230908304907343,
    0.40787306305798987
  ],
  "buffer_size": [
    340508,
    329670,
    182388,
    180171,
    301580,
    324630,
    319581,
    341435,
    318062,
    350835
  ],
  "learning_starts": [
    42,
    42,
    43,
    42,
    41,
    44,
    42,
    42,
    42,
    43
  ],
  "train_freq": [
    296,
    154,
    313,
    296,
    151,
    146,
    282,
    287,
    149,
    159
  ],
  "batch_size": [
    10,
    26,
    10,
    11,
    9,
    19,
    19,
    10,
    10,
    10
  ],
  "learning_rate": [
    0.001490357502632918,
    0.001649086308228726,
    0.0015097897074698786,
    0.001549290882402412,
    0.0015411472990586282,
    0.000833852747000762,
    0.0018355987069854107,
    0.0008442067875966097,
    0.0017492773712244306,
    0.0016553583157863404
  ],
  "gradient_steps": [
    275,
    261,
    218,
    292,
    280,
    274,
    281,
    210,
    212,
    207
  ],
  "tau": [
    0.0008781983710818836,
    0.0006333097660022774,
    0.0006388306111179769,
    0.0006311327104826877,
    0.0006351983845867663,
    0.0006283031400346111,
    0.0006356852128775718,
    0.0006413555584438574,
    0.0008818187592356293,
    0.0008625205125416955
  ],
  "policy_delay": [
    3,
    3,
    3,
    3,
    3,
    3,
    4,
    3,
    3,
    3
  ],
  "actnoise_type": [
    "ornstein",
    "ornstein",
    "ornstein",
    "ornstein",
    "ornstein",
    "ornstein",
    "ornstein",
    "ornstein",
    "ornstein",
    "ornstein"
  ],
  "actnoise_freqrel": [
    0.03657466901742217,
    0.037261894139307916,
    0.044168344680222266,
    0.044555123832326016,
    0.039342348242237535,
    0.038410562454807846,
    0.03479543548543921,
    0.03492028487829308,
    0.04408815211940141,
    0.04342546892260523
  ],
  "actnoise_stdrel": [
    0.014052559988374744,
    0.013775036254176398,
    0.014146720077608338,
    0.014000614861251332,
    0.014195582547307002,
    0.014067936028524726,
    0.016928285014279336,
    0.01388348269311803,
    0.014055665125100581,
    0.014182345020442874
  ],
  "target_policy_noise": [
    0.0068053921328515695,
    0.0071044785138926455,
    0.006737095735133849,
    0.00752723379890282,
    0.007093473174610996,
    0.007229397310388395,
    0.006395693890813284,
    0.007389125348648795,
    0.007876821880180329,
    0.007145201928507655
  ],
  "target_noise_clip": [
    0.08592143522718293,
    0.1307414056027202,
    0.17457334555280615,
    0.08059703830089632,
    0.0872655433941158,
    0.17596412709318418,
    0.08107794517332659,
    0.09681977572364518,
    0.09063062093193057,
    0.08593084047601177
  ],
  "random_exploration": 0.0,
  "num_envs": 4,
  "results_dir_name": "results",
  "storage_dir_name": "storage",
  "train_set": "remaining",
  "eval_set": "remaining",
  "OPENAI_LOG_FORMAT": "csv",
  "walltime_hrs": 2,
  "num_checkpoints": 100,
  "eval_ntrajs": 10,
  "eval_nsteps": 200,
  "eval_seed": 12345,
  "looping_tree": {
    "method": "fixed",
    "environment": "fixed",
    "total_timesteps": "fixed",
    "rng_seed": "cartesian",
    "policy_kwargs": "fixed",
    "gamma": "zip",
    "buffer_size": "zip",
    "learning_starts": "zip",
    "train_freq": "zip",
    "batch_size": "zip",
    "learning_rate": "zip",
    "gradient_steps": "zip",
    "tau": "zip",
    "policy_delay": "zip",
    "actnoise_type": "zip",
    "actnoise_freqrel": "zip",
    "actnoise_stdrel": "zip",
    "target_policy_noise": "zip",
    "target_noise_clip": "zip",
    "random_exploration": "fixed"
  }
}